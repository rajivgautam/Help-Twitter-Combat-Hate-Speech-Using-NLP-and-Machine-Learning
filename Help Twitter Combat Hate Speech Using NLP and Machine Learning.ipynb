{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help Twitter Combat Hate Speech Using NLP and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>DESCRIPTION\n",
    "\n",
    "Using NLP and ML, make a model to identify hate speech (racist or sexist tweets) in Twitter.\n",
    "\n",
    "<b>Problem Statement:  \n",
    "\n",
    "Twitter is the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being used as a medium  to spread hate. \n",
    "\n",
    "You are a data scientist at Twitter, and you will help Twitter in identifying the tweets with hate speech and removing them from the platform. You will use NLP techniques, perform specific cleanup for tweets data, and make a robust model.\n",
    "\n",
    "<b>Domain:</b> Social Media\n",
    "\n",
    "<b>Analysis to be done:</b> Clean up tweets and build a classification model by using NLP techniques, cleanup specific for tweets data, regularization and hyperparameter tuning using stratified k-fold and cross validation to get the best model.\n",
    "\n",
    "<b>Content: \n",
    "\n",
    "id: identifier number of the tweet\n",
    "\n",
    "Label: 0 (non-hate) /1 (hate)\n",
    "\n",
    "Tweet: the text in the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the tweets file using read_csv function from Pandas package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('TwitterHate.csv', encoding=\"utf-8\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the tweets into a list for easy text cleanup and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['tweet', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0   @user when a father is dysfunctional and is s...      0\n",
       "1  @user @user thanks for #lyft credit i can't us...      0\n",
       "2                                bihday your majesty      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. To cleanup: \n",
    "\n",
    "    1. Normalize the casing.\n",
    "\n",
    "    2. Using regular expressions, remove user handles. These begin with '@’.\n",
    "\n",
    "    3. Using regular expressions, remove URLs.\n",
    "\n",
    "    4. Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
    "\n",
    "    5. Remove stop words.\n",
    "\n",
    "    6. Remove redundant terms like ‘amp’, ‘rt’, etc.\n",
    "\n",
    "    7. Remove ‘#’ symbols from the tweet while retaining the term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet_text(tweet):\n",
    "    # Normalize the casing.\n",
    "    tweet.lower()    \n",
    "    \n",
    "    tweet = re.sub('[^A-Za-z0-9]+', ' ', tweet)\n",
    "    \n",
    "    # Remove user @ references and '#' from tweet\n",
    "    tweet = re.sub(r'\\@\\w+|\\#','', tweet)\n",
    "    \n",
    "    # Remove urls\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    #Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
    "    tk = TweetTokenizer()\n",
    "    tweet_tokens = tk.tokenize(tweet) \n",
    "    \n",
    "    # Remove stopwords\n",
    "    filtered_words = [w for w in tweet_tokens if not w in stop_words] \n",
    "    \n",
    "    # Remove redundant terms like ‘amp’, ‘rt’, etc.    \n",
    "    filtered_words_final = [w for w in filtered_words if not w in ('amp', 'rt')]   \n",
    "                \n",
    "    return \" \".join(filtered_words_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tweet = data['tweet'].apply(preprocess_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user user thanks lyft credit use cause offer w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  user father dysfunctional selfish drags kids d...      0\n",
       "1  user user thanks lyft credit use cause offer w...      0\n",
       "2                                     bihday majesty      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extra cleanup by removing terms with a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user user thanks lyft credit use cause offer w...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  length\n",
       "0  user father dysfunctional selfish drags kids d...      0      60\n",
       "1  user user thanks lyft credit use cause offer w...      0      87\n",
       "2                                     bihday majesty      0      14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['length']= data['tweet'].apply(len)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['length'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['length'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31949"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['length']>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13038</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15434</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20261</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22709</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25629</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29803</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31781</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet  label  length\n",
       "3351             0       0\n",
       "7222             0       0\n",
       "10461            0       0\n",
       "13038            0       0\n",
       "15434            0       0\n",
       "16250            0       0\n",
       "20261            0       0\n",
       "22709            0       0\n",
       "25629            1       0\n",
       "29803            1       0\n",
       "31781            0       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['length'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['length']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31949, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user user thanks lyft credit use cause offer w...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  length\n",
       "0  user father dysfunctional selfish drags kids d...      0      60\n",
       "1  user user thanks lyft credit use cause offer w...      0      87\n",
       "2                                     bihday majesty      0      14"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check out the top terms in the tweets:\n",
    "\n",
    "    1. First, get all the tokenized terms into one large list.\n",
    "    2. Use the counter and find the 10 most common terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_text(text):\n",
    "    # tokenize the text into a list of words\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final list with tokenized words\n",
    "tokenized_large = []\n",
    "\n",
    "# Iterating over each string in data\n",
    "for x in data['tweet']:\n",
    "    # Calliing preprocess text function\n",
    "    token = token_text(x)\n",
    "\n",
    "    tokenized_large.append(token) \n",
    "\n",
    "flattened_tokeninized_final = [i for j in tokenized_large for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(flattened_tokeninized_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user', 'love', 'day', 'happy', 'u', 'life', 'time', 'like', 'today', 'new']\n"
     ]
    }
   ],
   "source": [
    "# Use the counter and find the 10 most common terms.\n",
    "from collections import Counter\n",
    "most_common_words= [word for word, word_count in Counter(flattened_tokeninized_final).most_common(10)]\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data formatting for predictive modeling:\n",
    "\n",
    "    1. Join the tokens back to form strings. This will be required for the vectorizers.\n",
    "    2. Assign x and y.\n",
    "    3. Perform train_test_split using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user user thanks lyft credit use cause offer w...</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  length\n",
       "0  user father dysfunctional selfish drags kids d...      0      60\n",
       "1  user user thanks lyft credit use cause offer w...      0      87\n",
       "2                                     bihday majesty      0      14\n",
       "3                        model love u take u time ur      0      27\n",
       "4                      factsguide society motivation      0      29"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31949, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['tweet']\n",
    "Y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y ,test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. We’ll use TF-IDF values for the terms as a feature to get into a vector space model.\n",
    "\n",
    "    1. Import TF-IDF  vectorizer from sklearn.\n",
    "\n",
    "    2. Instantiate with a maximum of 5000 terms in your vocabulary.\n",
    "\n",
    "    3. Fit and apply on the train set.\n",
    "\n",
    "    4. Apply on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import TF-IDF  vectorizer from sklearn.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instantiate with a maximum of 5000 terms in your vocabulary.\n",
    "tfidf_vect = TfidfVectorizer(max_features =5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit and apply on the train set.\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Apply on the test set.\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model building: Ordinary Logistic Regression\n",
    "\n",
    "    1. Instantiate Logistic Regression from sklearn with default parameters.\n",
    "\n",
    "    2. Fit into  the train data.\n",
    "\n",
    "    3. Make predictions for the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the train and the test set.\n",
    "predictions_train = lr.predict(X_train_tfidf)\n",
    "predictions_test = lr.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Model evaluation: Accuracy, recall, and f_1 score.\n",
    "\n",
    "    1. Report the accuracy on the train set.\n",
    "\n",
    "    2. Report the recall on the train set: decent, high, or low.\n",
    "\n",
    "    3. Get the f1 score on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5965\n",
      "           1       0.93      0.35      0.51       425\n",
      "\n",
      "    accuracy                           0.95      6390\n",
      "   macro avg       0.94      0.67      0.74      6390\n",
      "weighted avg       0.95      0.95      0.95      6390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall :  0.34823529411764703\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall : \", recall_score(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is 34%. ie Sensitivity or true positive rate is 34%, which is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score :  0.5068493150684932\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score : \",f1_score(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9549295774647887\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Looks like you need to adjust the class imbalance, as the model seems to focus on the 0s.\n",
    "\n",
    "    1. Adjust the appropriate class in the LogisticRegression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of label')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Distribution of label\", size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929888\n",
       "1    0.070112\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution\n",
    "data['label'].value_counts()/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class weights\n",
    "w = {0:1, 1:92} # lable distribution % is 1:0==7:92\n",
    "\n",
    "lr_2 = LogisticRegression(random_state=11, class_weight=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Train again with the adjustment and evaluate.\n",
    "\n",
    "    1. Train the model on the train set.\n",
    "\n",
    "    2. Evaluate the predictions on the train set: accuracy, recall, and f_1 score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 92}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=11, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_2.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = lr_2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8539906103286385\n",
      "  Recall :  0.8870588235294118\n",
      "f1_score :  0.4469472436277415\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : \", accuracy_score(y_test, predictions_2))\n",
    "print(\"  Recall : \", recall_score(y_test, predictions_2))\n",
    "print(\"f1_score : \", f1_score(y_test, predictions_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Regularization and Hyperparameter tuning:\n",
    "\n",
    "    1. Import GridSearch and StratifiedKFold because of class imbalance.\n",
    "\n",
    "    2. Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters.\n",
    "\n",
    "    3. Use a balanced class weight while instantiating the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_val = np.arange(0.5, 20.0, 0.5)\n",
    "penalty_val = [\"l1\", \"l2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid = {\"penalty\": penalty_val, \"C\": C_val }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_3 = LogisticRegression(random_state=11, class_weight=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Find the parameters with the best recall in cross validation.\n",
    "\n",
    "    1. Choose ‘recall’ as the metric for scoring.\n",
    "\n",
    "    2. Choose stratified 4 fold cross validation scheme.\n",
    "\n",
    "    3. Fit into  the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(lr_3, hyperparam_grid, scoring=\"recall\", cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. What are the best parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best recall: {grid.best_score_} with param: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Predict and evaluate using the best estimator.\n",
    "\n",
    "    1. Use the best estimator from the grid search to make predictions on the test set.\n",
    "\n",
    "    2. What is the recall on the test set for the toxic comments?\n",
    "\n",
    "    3. What is the f_1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_4 = LogisticRegression(random_state=11, class_weight=w, C=0.5, penalty='l2')\n",
    "lr_4.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_4.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : \", accuracy_score(y_test, predictions))\n",
    "print(\"  Recall : \", recall_score(y_test, predictions))\n",
    "print(\"f1_score : \", f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
